{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"ZgHMgFFUkluX"},"outputs":[],"source":["import csv\n","import random\n","import pandas\n","import numpy as np\n","import json\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.metrics import classification_report,confusion_matrix\n","import cv2\n","import os"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HUpNP7J9kluY","outputId":"9d757597-9444-4168-8e86-f93f6a2d345b"},"outputs":[],"source":["memedata = []\n","with open(\"../data/train.jsonl\", \"r\") as f:\n","    for line in f:\n","        memedata.append(json.loads(line))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AvrwLel-kluZ","outputId":"f9e75229-21fd-40a9-cd8c-9d4c60c0404b"},"outputs":[],"source":["meme_data = []\n","for elem in memedata:\n","    elem['label']=1\n","    meme_data.append(elem)\n","\n","meme_paths = []\n","for elem in meme_data:\n","    meme_paths.append({'label': elem['label'],'path': elem['img'],}) \n","\n","\n","# print(meme_paths)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Gxp4ySckklua","outputId":"9e3ab8f0-ee42-4fb8-d9f2-4a760b878e10"},"outputs":[],"source":["normal_img_data = []\n","import pandas as pd\n","df = pd.read_csv('../train.csv')\n","normal_img_data = df.to_dict(orient='records')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UPhHHXhCklua","outputId":"862dc0ce-cfbc-4706-9ad1-7e5a67122c5d"},"outputs":[],"source":["for elem in normal_img_data:\n","    elem['path'] = elem['Image']\n","    elem['label'] = 0\n","\n","normal_img_data2=[]\n","for elem in normal_img_data:\n","    normal_img_data2.append({'label' : 0, 'path' : elem['path']})\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8DWjuCmNklub","outputId":"b28cc3ea-1bee-4b3c-ba07-9853c3e89eab"},"outputs":[],"source":["img_data_list = meme_data + normal_img_data2\n","random.shuffle(img_data_list)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yXnpi1i5klub","outputId":"660949de-de89-4ff6-f7e0-66cec295d057"},"outputs":[],"source":["print(len(img_data_list))"]},{"cell_type":"markdown","metadata":{},"source":["I have used this model from the internet"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"74-9HItLklub"},"outputs":[],"source":["import torch\n","final =[]\n","X = []\n","Y=[]\n","img_size = (224,224)\n","for elem in img_data_list:\n","    img_arr = cv2.imread(elem['path'])\n","    img_arr_rgb = cv2.cvtColor(img_arr, cv2.COLOR_BGR2RGB)\n","    resized_arr = cv2.resize(img_arr_rgb, img_size)\n","    transposed_tensor = np.transpose(resized_arr, (2, 0, 1))\n","    t = torch.tensor(transposed_tensor)\n","    X.append(t)\n","\n","    Y.append(elem['label'])\n","\n","X_final = np.array(X)\n","X_tensor = torch.tensor(X_final)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LKYKx8H6nlbj"},"outputs":[],"source":["import pickle\n","with open('../tensor.pkl', 'rb') as f:\n","    loaded_tensor = pickle.load(f)\n","with open('../label.pkl', 'rb') as f:\n","    Y = pickle.load(f)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4167,"status":"ok","timestamp":1708221049412,"user":{"displayName":"Hemang Jain","userId":"10151840650494923904"},"user_tz":-330},"id":"9mhlWRQmklue","outputId":"9c0e6171-d9f9-4ba1-cb0b-56571c342e03"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torchvision import transforms\n","\n","class Net(nn.Module):\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)  # input channels=3, output channels=32, kernel_size=3x3\n","        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)  # Max pooling layer with kernel_size=2x2, stride=2\n","        self.conv2 = nn.Conv2d(32, 32, kernel_size=3, padding=1)  # input channels=32, output channels=32, kernel_size=3x3\n","        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)  # input channels=32, output channels=64, kernel_size=3x3\n","        self.dropout = nn.Dropout2d(p=0.4)  # Dropout layer with dropout probability 0.4\n","        self.fc1 = nn.Linear(64 * 28 * 28, 128)  # Fully connected layer with input features 64*28*28 and output features 128\n","        self.fc2 = nn.Linear(128, 2)  # Fully connected layer with input features 128 and output features 2 (for binary classification)\n","\n","    def forward(self, x):\n","        x = F.relu(self.conv1(x))  # Apply first convolutional layer followed by ReLU activation\n","        x = self.pool(x)  # Apply max pooling\n","        x = F.relu(self.conv2(x))  # Apply second convolutional layer followed by ReLU activation\n","        x = self.pool(x)  # Apply max pooling\n","        x = F.relu(self.conv3(x))  # Apply third convolutional layer followed by ReLU activation\n","        x = self.pool(x)  # Apply max pooling\n","        x = self.dropout(x)  # Apply dropout\n","        x = x.view(-1, 64 * 28 * 28)  # Reshape the tensor\n","        x = F.relu(self.fc1(x))  # Apply first fully connected layer followed by ReLU activation\n","        x = self.fc2(x)  # Apply second fully connected layer\n","        return F.softmax(x, dim=1)  # Apply softmax activation for classification\n","\n","# Instantiate the model\n","model = Net()\n","\n","# Print model summary\n","print(model)\n","\n","import torch.optim as optim\n","\n","# Define the optimizer\n","optimizer = optim.Adam(model.parameters(), lr=0.000001)\n","\n","# Define the loss function\n","criterion = nn.CrossEntropyLoss()\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3877308,"status":"ok","timestamp":1708224941714,"user":{"displayName":"Hemang Jain","userId":"10151840650494923904"},"user_tz":-330},"id":"1i-qtzfqklue","outputId":"16ee4f4e-6446-40be-e229-be475a9897b2"},"outputs":[],"source":["import torch\n","import torch.optim as optim\n","import torch.nn.functional as F\n","\n","image_tensors =loaded_tensor\n","print(image_tensors)\n","labels = torch.tensor(Y)\n","batch_size = 32\n","epochs = 5\n","for epoch in range(epochs):\n","    indices = torch.randperm(len(image_tensors))\n","    print(indices)\n","    running_loss = 0.0\n","    correct_train = 0\n","    total_train = 0\n","\n","    for i in range(0, len(image_tensors), batch_size):\n","        batch_indices = indices[i:i+batch_size]\n","        print(i)\n","        batch_images = torch.stack([image_tensors[idx] for idx in batch_indices])\n","        batch_labels = torch.tensor([labels[idx] for idx in batch_indices])\n","\n","        optimizer.zero_grad()\n","\n","        outputs = model(batch_images)\n","        loss = criterion(outputs, batch_labels)\n","\n","        # Backward pass and optimization\n","        loss.backward()\n","        optimizer.step()\n","\n","        # Accumulate loss\n","        running_loss += loss.item()\n","\n","        # Calculate accuracy\n","        _, predicted = torch.max(outputs.data, 1)\n","        total_train += batch_labels.size(0)\n","        correct_train += (predicted == batch_labels).sum().item()\n","\n","    # Calculate average training loss and accuracy\n","    train_loss = running_loss / (len(image_tensors) / batch_size)\n","    train_accuracy = correct_train / total_train\n","\n","    # Print progress\n","    print(f'Epoch [{epoch+1}/{epochs}], '\n","          f'Training Loss: {train_loss:.4f}, Training Accuracy: {train_accuracy:.4f}')\n","\n","# Training finished\n","print('Finished Training')\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":211},"executionInfo":{"elapsed":6344,"status":"error","timestamp":1707978465991,"user":{"displayName":"Hemang Jain","userId":"10151840650494923904"},"user_tz":-330},"id":"3MpLCVVkvE6g","outputId":"3b322492-3e7a-4b5f-de16-7729d0e36a1a"},"outputs":[],"source":["import torch\n","from PIL import Image\n","from torchvision import transforms\n","\n","model_path = 'model.pkl'\n","with open(model_path, 'rb') as f:\n","    loaded_model = pickle.load(f)\n","\n","def preprocess_image(image_path):\n","    image = Image.open(image_path)\n","    transform = transforms.Compose([\n","        transforms.Resize((224, 224)),  # Resize the image to the size expected by the model\n","        transforms.ToTensor(),           # Convert the image to a PyTorch tensor\n","        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize the image\n","    ])\n","    processed_image = transform(image)\n","    processed_image = processed_image.unsqueeze(0)\n","    return processed_image\n","\n","def predict_image(model, processed_image):\n","    model.eval()\n","    with torch.no_grad():\n","        outputs = model(processed_image)\n","    return outputs\n","\n","image_path = '../data/img/01235.png'\n","\n","processed_image = preprocess_image(image_path)\n","\n","outputs = predict_image(loaded_model, processed_image)\n","\n","print(outputs)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":386,"status":"ok","timestamp":1708231354449,"user":{"displayName":"Hemang Jain","userId":"10151840650494923904"},"user_tz":-330},"id":"HWcZwdIp2kJu"},"outputs":[],"source":["img = \"../data/img/01245.png\""]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":660,"status":"ok","timestamp":1708231358679,"user":{"displayName":"Hemang Jain","userId":"10151840650494923904"},"user_tz":-330},"id":"x2Gp32HW2FC2"},"outputs":[],"source":["import torch\n","img_size = (224,224)\n","img_arr = cv2.imread(img)\n","img_arr_rgb = cv2.cvtColor(img_arr, cv2.COLOR_BGR2RGB)\n","resized_arr = cv2.resize(img_arr_rgb, img_size)\n","transposed_tensor = np.transpose(resized_arr, (2, 0, 1))\n","t = torch.tensor(transposed_tensor).float()"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":391,"status":"ok","timestamp":1708231362651,"user":{"displayName":"Hemang Jain","userId":"10151840650494923904"},"user_tz":-330},"id":"WWHKRUAT26Vw"},"outputs":[],"source":["import pickle\n","model_path = \"model.pkl\"\n","with open(model_path, 'rb') as f:\n","    loaded_model = pickle.load(f)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":392,"status":"ok","timestamp":1708231365003,"user":{"displayName":"Hemang Jain","userId":"10151840650494923904"},"user_tz":-330},"id":"2PKD68n63JrN","outputId":"6e70ff05-82d8-429e-cd83-9c40cc5ebc28"},"outputs":[],"source":["loaded_model.eval()\n","with torch.no_grad():\n","    outputs = loaded_model(t)\n","print(outputs[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":394,"status":"ok","timestamp":1708236955575,"user":{"displayName":"Hemang Jain","userId":"10151840650494923904"},"user_tz":-330},"id":"GtHu8K7e15Fe"},"outputs":[],"source":["import glob\n","\n","image_file1=glob.glob('../data/img/*.png')\n","image_files2 = glob.glob('../images/*.jpg')\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def process_images(image_file):\n","    for i in image_file:\n","        actual_negative=0\n","        not_positive=0\n","        img_size = (224,224)\n","        img_arr = cv2.imread(i)\n","        img_arr_rgb = cv2.cvtColor(img_arr, cv2.COLOR_BGR2RGB)\n","        resized_arr = cv2.resize(img_arr_rgb, img_size)\n","        transposed_tensor = np.transpose(resized_arr, (2, 0, 1))\n","        t = torch.tensor(transposed_tensor).float()\n","        with torch.no_grad():\n","            outputs = loaded_model(t)\n","            outputs = outputs.tolist()\n","        if outputs[0][0]>outputs[0][1]:\n","            actual_negative+=1\n","        else:\n","            not_positive +=1\n","    return actual_negative,not_positive"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":660556,"status":"ok","timestamp":1708237820257,"user":{"displayName":"Hemang Jain","userId":"10151840650494923904"},"user_tz":-330},"id":"52GevOcF2DFu","outputId":"b52ff320-df9c-41cb-9bab-de6393d5005d"},"outputs":[],"source":["actual_negative,not_positive=process_images(image_file1)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["actual_negative2,not_positive2=process_images(image_files2)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":402,"status":"ok","timestamp":1708238093226,"user":{"displayName":"Hemang Jain","userId":"10151840650494923904"},"user_tz":-330},"id":"sdu_473G6wgj","outputId":"621725b4-eaea-4ce4-daee-70ff3822f0a2"},"outputs":[],"source":["accuracy = 1 - (actual_negative + not_positive )/len(image_file1)\n","print(accuracy)\n","accuracy = 1 - (actual_negative2 + not_positive2 )/len(image_file1)\n","print(accuracy)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":0}
